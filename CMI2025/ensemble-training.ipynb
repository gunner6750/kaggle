{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/llkh0a/ensemble-training?scriptVersionId=244414570\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Ensemble Modeling for BFRB Sensor Data Classification\n\nThis notebook demonstrates an ensemble approach for classifying body-focused repetitive behaviors (BFRBs) using sensor data from the CMI competition. The following models are used in the ensemble:\n\n- **LightGBM**\n- **XGBoost**\n- **CatBoost**\n\n## Feature Selection\n\nFeatures are constructed as follows:\n- For each sequence, statistical features (mean, std, min, max) are extracted from all numeric sensor columns (IMU, thermopile, ToF, etc.).\n- Demographic features from the `train_demographics.csv` file (such as age, sex, handedness, height, etc.) are merged and included as input features for the models.\n- The final feature set for each sequence includes all aggregated sensor statistics and all demographic columns except for the subject identifier.","metadata":{}},{"cell_type":"markdown","source":"for model submission checkout this notebook: https://www.kaggle.com/code/llkh0a/ensemble-inference/","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration\nExplore the data: check shapes, columns, and some basic statistics.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Read data\ntrain = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv')\ntrain_demo = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv')\n\nprint('Train shape:', train.shape)\nprint('Train demographics shape:', train_demo.shape)\nprint('Train columns:', train.columns.tolist())\nprint(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T16:24:27.910978Z","iopub.execute_input":"2025-06-08T16:24:27.911234Z","iopub.status.idle":"2025-06-08T16:25:00.038366Z","shell.execute_reply.started":"2025-06-08T16:24:27.911191Z","shell.execute_reply":"2025-06-08T16:25:00.037739Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning\nCheck and handle missing values and outliers in sensor data.","metadata":{}},{"cell_type":"code","source":"# Check missing values\nmissing = train.isnull().sum()\nprint('Missing values per column:')\nprint(missing[missing > 0])\n\n# Replace -1 in ToF columns with NaN for easier statistics\ntof_cols = [col for col in train.columns if col.startswith('tof_')]\ntrain[tof_cols] = train[tof_cols].replace(-1, np.nan)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T16:25:00.039587Z","iopub.execute_input":"2025-06-08T16:25:00.039774Z","iopub.status.idle":"2025-06-08T16:25:02.712799Z","shell.execute_reply.started":"2025-06-08T16:25:00.03976Z","shell.execute_reply":"2025-06-08T16:25:02.712256Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering\nExtract statistical features for each sequence and merge with demographics.","metadata":{}},{"cell_type":"code","source":"def extract_features(df):\n    feats = []\n    # Only use numeric columns for aggregation\n    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n    # Remove columns that should not be aggregated\n    exclude_cols = ['row_id', 'sequence_id', 'sequence_counter', 'subject']\n    numeric_cols = [c for c in numeric_cols if c not in exclude_cols]\n    for seq_id, group in df.groupby('sequence_id'):\n        feat = {'sequence_id': seq_id}\n        for col in numeric_cols:\n            feat[col + '_mean'] = group[col].mean()\n            feat[col + '_std'] = group[col].std()\n            feat[col + '_min'] = group[col].min()\n            feat[col + '_max'] = group[col].max()\n        feat['subject'] = group['subject'].iloc[0]\n        feats.append(feat)\n    return pd.DataFrame(feats)\n\nX = extract_features(train)\n# Merge demographic features (excluding subject key)\ndemographic_features = [col for col in train_demo.columns if col != 'subject']\nX = X.merge(train_demo, on='subject', how='left')\n# Fill any remaining missing values in features with column mean (or 0 as fallback)\nX = X.fillna(X.mean(numeric_only=True)).fillna(0)\n# Add demographic features to training set\nfeature_cols = [col for col in X.columns if col not in ['sequence_id', 'subject']]\ny = train.groupby('sequence_id')['gesture'].first().values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T16:25:02.715578Z","iopub.execute_input":"2025-06-08T16:25:02.715735Z","iopub.status.idle":"2025-06-08T16:29:28.793327Z","shell.execute_reply.started":"2025-06-08T16:25:02.715722Z","shell.execute_reply":"2025-06-08T16:29:28.792759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny_enc = le.fit_transform(y)\njoblib.dump(le, 'label_encoder.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T16:30:05.204002Z","iopub.execute_input":"2025-06-08T16:30:05.204311Z","iopub.status.idle":"2025-06-08T16:30:05.212742Z","shell.execute_reply.started":"2025-06-08T16:30:05.204289Z","shell.execute_reply":"2025-06-08T16:30:05.212158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print label map\nlabel_map = {i: label for i, label in enumerate(le.classes_)}\nprint('Label map:', label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T16:41:50.284565Z","iopub.execute_input":"2025-06-08T16:41:50.285363Z","iopub.status.idle":"2025-06-08T16:41:50.289941Z","shell.execute_reply.started":"2025-06-08T16:41:50.285336Z","shell.execute_reply":"2025-06-08T16:41:50.289135Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training & Ensemble\nTrain LightGBM, XGBoost, CatBoost models and ensemble their predictions.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nimport joblib\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X[feature_cols], y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n\nlgbm = LGBMClassifier()\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\ncat = CatBoostClassifier(verbose=0)\n\nensemble = VotingClassifier(estimators=[\n    ('lgbm', lgbm),\n    ('xgb', xgb),\n    ('cat', cat)\n], voting='soft')\n\nensemble.fit(X_train, y_train)\ny_pred = ensemble.predict(X_val)\nprint('Validation accuracy:', accuracy_score(y_val, y_pred))\n\n# Save the ensemble model to a file\njoblib.dump(ensemble, 'ensemble_model.joblib')\nprint('Model saved as ensemble_model.joblib')","metadata":{},"outputs":[],"execution_count":null}]}